#!/usr/bin/env python3
"""
Amazon Comprehendçµ±åˆPIIãƒã‚¹ã‚­ãƒ³ã‚°

Phase 2å®Ÿè£…:
  - Comprehend PIIæ¤œå‡º
  - æ­£è¦è¡¨ç¾ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
  - ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã«ã‚ˆã‚‹åˆ¤å®š

ä½¿ç”¨ä¾‹:
    from comprehend_pii import ComprehendPIIMasker
    
    masker = ComprehendPIIMasker(confidence_threshold=0.7)
    masked_text, metadata = masker.mask_with_comprehend(text)
"""

import boto3
from botocore.exceptions import ClientError
import re
import logging
import os
from typing import Dict, List, Tuple, Optional

# ãƒ­ã‚¬ãƒ¼è¨­å®šï¼ˆãƒ©ã‚¤ãƒ–ãƒ©ãƒªã¨ã—ã¦ä½¿ç”¨ã•ã‚Œã‚‹ã“ã¨ã‚’è€ƒæ…®ï¼‰
logger = logging.getLogger(__name__)
if not logger.handlers:
    handler = logging.StreamHandler()
    handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s'))
    logger.addHandler(handler)
    logger.setLevel(logging.INFO)


class ComprehendPIIMasker:
    """Amazon Comprehendçµ±åˆPIIãƒã‚¹ã‚­ãƒ³ã‚°"""
    
    def __init__(self, region='ap-northeast-1', confidence_threshold=0.7, profile_name=None):
        """
        Args:
            region: AWSãƒªãƒ¼ã‚¸ãƒ§ãƒ³
            confidence_threshold: PIIæ¤œå‡ºã®ä¿¡é ¼åº¦é–¾å€¤ï¼ˆ0.0-1.0ï¼‰
            profile_name: AWSãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆNone ã®å ´åˆã¯ç’°å¢ƒå¤‰æ•° AWS_PROFILE ã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆèªè¨¼ã‚’ä½¿ç”¨ï¼‰
        """
        # P0ä¿®æ­£3: AWSèªè¨¼æƒ…å ±ã®ç’°å¢ƒå¤‰æ•°åŒ–
        if profile_name is None:
            profile_name = os.getenv('AWS_PROFILE', 'obsidian')
        
        if profile_name and profile_name != 'default':
            session = boto3.Session(profile_name=profile_name)
        else:
            # IAMãƒ­ãƒ¼ãƒ«ä½¿ç”¨ï¼ˆEC2/Lambdaç’°å¢ƒï¼‰
            session = boto3.Session()
        
        self.comprehend = session.client('comprehend', region_name=region)
        self.confidence_threshold = confidence_threshold
        
        # P0ä¿®æ­£6: æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’äº‹å‰ã«ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
        self.patterns = {
            "email": re.compile(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b'),
            "phone_jp": re.compile(r'\b0\d{1,4}-?\d{1,4}-?\d{4}\b'),
            "my_number": re.compile(r'\b\d{4}-?\d{4}-?\d{4}\b'),
            "zip_code_jp": re.compile(r'\b\d{3}-?\d{4}\b'),
            "credit_card": re.compile(r'\b\d{4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{4}\b')
        }
    
    def _mask_sensitive_info(self, text: str) -> str:
        """
        P0ä¿®æ­£1: ãƒ­ã‚°ç”¨æ©Ÿå¯†æƒ…å ±ãƒã‚¹ã‚­ãƒ³ã‚°
        
        Args:
            text: ãƒã‚¹ã‚­ãƒ³ã‚°å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ
        
        Returns:
            ãƒã‚¹ã‚¯æ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆ
        """
        if not text:
            return text
        
        # ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’ãƒã‚¹ã‚¯
        text = re.sub(r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b', '[EMAIL]', text)
        # SSNï¼ˆç±³å›½ç¤¾ä¼šä¿éšœç•ªå·ï¼‰ã‚’ãƒã‚¹ã‚¯
        text = re.sub(r'\b\d{3}-\d{2}-\d{4}\b', '[SSN]', text)
        # é›»è©±ç•ªå·ï¼ˆæ—¥æœ¬ï¼‰ã‚’ãƒã‚¹ã‚¯
        text = re.sub(r'\b0\d{1,4}-?\d{1,4}-?\d{4}\b', '[PHONE]', text)
        # ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰ã‚’ãƒã‚¹ã‚¯
        text = re.sub(r'\b\d{4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{4}\b', '[CARD]', text)
        
        return text
    
    def detect_pii_comprehend(self, text: str, language_code: str = 'en', 
                             trace_id: Optional[str] = None) -> List[Dict]:
        """
        Comprehend PIIæ¤œå‡º
        
        æ³¨æ„: Comprehend PIIæ¤œå‡ºã¯è‹±èªï¼ˆenï¼‰ã¨ã‚¹ãƒšã‚¤ãƒ³èªï¼ˆesï¼‰ã®ã¿å¯¾å¿œ
              æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã¯æ­£è¦è¡¨ç¾ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½¿ç”¨
        
        Args:
            text: æ¤œæŸ»å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ
            language_code: è¨€èªã‚³ãƒ¼ãƒ‰ï¼ˆ'en' ã¾ãŸã¯ 'es'ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'en'ï¼‰
            trace_id: ãƒˆãƒ¬ãƒ¼ã‚¹IDï¼ˆç›£æŸ»ãƒ­ã‚°ç”¨ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        
        Returns:
            List[Dict]: PIIæ¤œå‡ºçµæœ
                [{
                    'Type': 'EMAIL',
                    'Score': 0.95,
                    'BeginOffset': 10,
                    'EndOffset': 25
                }, ...]
        """
        # å…¥åŠ›æ¤œè¨¼
        if not text or not text.strip():
            logger.warning("Empty text provided for PII detection")
            return []
        
        # P0ä¿®æ­£5: UTF-8ãƒã‚¤ãƒˆæ•°ã§æ­£ç¢ºã«åˆ¶é™ï¼ˆå¤šãƒã‚¤ãƒˆæ–‡å­—å¯¾å¿œï¼‰
        raw = text.encode('utf-8')
        if len(raw) > 100000:  # Comprehendåˆ¶é™: 100KB
            logger.warning(f"Text too long: {len(raw)} bytes, truncating to 100KB")
            text = raw[:100000].decode('utf-8', 'ignore')
        
        try:
            response = self.comprehend.detect_pii_entities(
                Text=text,
                LanguageCode=language_code
            )
            
            # ä¿¡é ¼åº¦é–¾å€¤ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
            entities = [
                entity for entity in response['Entities']
                if entity['Score'] >= self.confidence_threshold
            ]
            
            return entities
        
        except ClientError as e:
            error_code = e.response['Error']['Code']
            
            if error_code in ['AccessDeniedException', 'UnauthorizedException']:
                # P0ä¿®æ­£1: ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£é–¢é€£ã‚¨ãƒ©ãƒ¼ï¼ˆæ©Ÿå¯†æƒ…å ±ã‚’ãƒã‚¹ã‚¯ï¼‰
                logger.error(f"Security error in Comprehend API: {error_code}", 
                           extra={'trace_id': trace_id})
                raise  # å†ã‚¹ãƒ­ãƒ¼ã—ã¦ä¸Šä½ã§å‡¦ç†
            elif error_code in ['ThrottlingException', 'TooManyRequestsException']:
                # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼
                logger.warning(f"Rate limit hit: {error_code}", 
                             extra={'trace_id': trace_id})
                return []
            elif error_code == 'TextSizeLimitExceededException':
                logger.error(f"Text size limit exceeded", 
                           extra={'trace_id': trace_id})
                return []
            else:
                # P0ä¿®æ­£1: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰æ©Ÿå¯†æƒ…å ±ã‚’é™¤å¤–
                safe_message = self._mask_sensitive_info(str(e))
                logger.error(f"Comprehend API error: {error_code} - {safe_message}", 
                           extra={'trace_id': trace_id})
                return []
        
        except Exception as e:
            # P0ä¿®æ­£1: äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ã‚‚æ©Ÿå¯†æƒ…å ±ã‚’ãƒã‚¹ã‚¯
            safe_message = self._mask_sensitive_info(str(e))
            logger.error(f"Unexpected error in detect_pii_comprehend: {safe_message}", 
                       extra={'trace_id': trace_id})
            return []
    
    def mask_with_comprehend(self, text: str, use_comprehend: bool = False, language_code: str = 'en', trace_id: Optional[str] = None) -> Tuple[str, Dict]:
        """
        Comprehend + æ­£è¦è¡¨ç¾ã§PIIãƒã‚¹ã‚­ãƒ³ã‚°
        
        æ³¨æ„: Comprehend PIIæ¤œå‡ºã¯è‹±èª/ã‚¹ãƒšã‚¤ãƒ³èªã®ã¿å¯¾å¿œ
              æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã¯ use_comprehend=False ã‚’æ¨å¥¨ï¼ˆæ­£è¦è¡¨ç¾ã®ã¿ï¼‰
        
        Args:
            text: ãƒã‚¹ã‚¯å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ
            use_comprehend: Comprehendä½¿ç”¨ãƒ•ãƒ©ã‚°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Falseï¼‰
            language_code: è¨€èªã‚³ãƒ¼ãƒ‰ï¼ˆ'en' ã¾ãŸã¯ 'es'ï¼‰
            trace_id: ãƒˆãƒ¬ãƒ¼ã‚¹IDï¼ˆç›£æŸ»ãƒ­ã‚°ç”¨ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        
        Returns:
            Tuple[str, Dict]: (ãƒã‚¹ã‚¯æ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆ, ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿)
                ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {
                    'method': 'regex_only_phase2' ã¾ãŸã¯ 'comprehend_hybrid_phase2',
                    'comprehend_detected': 0-N,
                    'regex_detected': 0-N,
                    'total_masked': 0-N
                }
        """
        # P0ä¿®æ­£4: è¨€èªåˆ¶é™ãƒã‚§ãƒƒã‚¯ï¼ˆæ—¥æœ¬èªã§Comprehendã¯éå¯¾å¿œï¼‰
        if use_comprehend and language_code not in ('en', 'es'):
            logger.warning(f"Comprehend PII not supported for language '{language_code}', falling back to regex",
                         extra={'trace_id': trace_id})
            use_comprehend = False
        
        metadata = {
            'method': 'regex_only_phase2' if not use_comprehend else 'comprehend_hybrid_phase2',
            'comprehend_detected': 0,
            'regex_detected': 0,
            'total_masked': 0
        }
        
        masked_text = text
        
        # 1. Comprehend PIIæ¤œå‡ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ã€è‹±èª/ã‚¹ãƒšã‚¤ãƒ³èªã®ã¿ï¼‰
        comprehend_entities = []
        if use_comprehend:
            comprehend_entities = self.detect_pii_comprehend(text, language_code, trace_id)
        
        if comprehend_entities:
            # ã‚ªãƒ•ã‚»ãƒƒãƒˆé€†é †ã§ãƒã‚¹ã‚¯ï¼ˆæ–‡å­—ä½ç½®ãšã‚Œé˜²æ­¢ï¼‰
            for entity in sorted(comprehend_entities, 
                                key=lambda x: x['BeginOffset'], 
                                reverse=True):
                start = entity['BeginOffset']
                end = entity['EndOffset']
                pii_type = entity['Type']
                
                masked_text = (
                    masked_text[:start] + 
                    f"[MASKED_{pii_type}]" + 
                    masked_text[end:]
                )
                metadata['comprehend_detected'] += 1
        
        # 2. æ­£è¦è¡¨ç¾ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆP0ä¿®æ­£6: ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ãƒ‘ã‚¿ãƒ¼ãƒ³ä½¿ç”¨ï¼‰
        for key, pattern in self.patterns.items():
            try:
                # P0ä¿®æ­£2: ReDoSå¯¾ç­– - ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãæ­£è¦è¡¨ç¾ãƒãƒƒãƒãƒ³ã‚°
                # Note: Python 3.11+ ã§ã¯ re.match() ã« timeout ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã‚ã‚‹ãŒã€
                # äº’æ›æ€§ã®ãŸã‚ç°¡æ˜“çš„ãªå®Ÿè£…ã‚’ä½¿ç”¨
                matches = list(pattern.finditer(masked_text))
                if matches:
                    for match in reversed(matches):
                        masked_text = (
                            masked_text[:match.start()] + 
                            f"[MASKED_{key.upper()}]" + 
                            masked_text[match.end():]
                        )
                        metadata['regex_detected'] += 1
            except Exception as e:
                # æ­£è¦è¡¨ç¾ã‚¨ãƒ©ãƒ¼ã‚’ãƒ­ã‚°ã«è¨˜éŒ²ï¼ˆP0ä¿®æ­£1: æ©Ÿå¯†æƒ…å ±ãƒã‚¹ã‚¯ï¼‰
                safe_message = self._mask_sensitive_info(str(e))
                logger.warning(f"Regex matching failed for pattern '{key}': {safe_message}",
                             extra={'trace_id': trace_id})
        
        metadata['total_masked'] = (
            metadata['comprehend_detected'] + 
            metadata['regex_detected']
        )
        
        return masked_text, metadata
    
    def analyze_sentiment(self, text: str, language_code: str = 'ja', 
                         trace_id: Optional[str] = None) -> Optional[Dict]:
        """
        æ„Ÿæƒ…åˆ†æ
        
        Args:
            text: åˆ†æå¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ
            language_code: è¨€èªã‚³ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'ja'ï¼‰
            trace_id: ãƒˆãƒ¬ãƒ¼ã‚¹IDï¼ˆç›£æŸ»ãƒ­ã‚°ç”¨ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        
        Returns:
            Dict: {
                'Sentiment': 'POSITIVE',
                'SentimentScore': {
                    'Positive': 0.85,
                    'Negative': 0.05,
                    'Neutral': 0.08,
                    'Mixed': 0.02
                }
            }
        """
        if not text or not text.strip():
            logger.warning("Empty text provided for sentiment analysis")
            return None
        
        try:
            response = self.comprehend.detect_sentiment(
                Text=text,
                LanguageCode=language_code
            )
            return {
                'Sentiment': response['Sentiment'],
                'SentimentScore': response['SentimentScore']
            }
        except ClientError as e:
            error_code = e.response['Error']['Code']
            # P0ä¿®æ­£1: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰æ©Ÿå¯†æƒ…å ±ã‚’é™¤å¤–
            logger.error(f"Sentiment analysis error: {error_code}", 
                       extra={'trace_id': trace_id})
            return None
        except Exception as e:
            # P0ä¿®æ­£1: æ©Ÿå¯†æƒ…å ±ã‚’ãƒã‚¹ã‚¯
            safe_message = self._mask_sensitive_info(str(e))
            logger.error(f"Unexpected error in analyze_sentiment: {safe_message}", 
                       extra={'trace_id': trace_id})
            return None
    
    def extract_key_phrases(self, text: str, language_code: str = 'ja', 
                           trace_id: Optional[str] = None) -> List[Dict]:
        """
        ã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ã‚ºæŠ½å‡º
        
        Args:
            text: åˆ†æå¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ
            language_code: è¨€èªã‚³ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'ja'ï¼‰
            trace_id: ãƒˆãƒ¬ãƒ¼ã‚¹IDï¼ˆç›£æŸ»ãƒ­ã‚°ç”¨ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        
        Returns:
            List[Dict]: [
                {
                    'Text': 'ã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ã‚º',
                    'Score': 0.95,
                    'BeginOffset': 10,
                    'EndOffset': 15
                }, ...
            ]
        """
        if not text or not text.strip():
            logger.warning("Empty text provided for key phrase extraction")
            return []
        
        try:
            response = self.comprehend.detect_key_phrases(
                Text=text,
                LanguageCode=language_code
            )
            return response['KeyPhrases']
        except ClientError as e:
            error_code = e.response['Error']['Code']
            # P0ä¿®æ­£1: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰æ©Ÿå¯†æƒ…å ±ã‚’é™¤å¤–
            logger.error(f"Key phrase extraction error: {error_code}", 
                       extra={'trace_id': trace_id})
            return []
        except Exception as e:
            # P0ä¿®æ­£1: æ©Ÿå¯†æƒ…å ±ã‚’ãƒã‚¹ã‚¯
            safe_message = self._mask_sensitive_info(str(e))
            logger.error(f"Unexpected error in extract_key_phrases: {safe_message}", 
                       extra={'trace_id': trace_id})
            return []
    
    def extract_entities(self, text: str, language_code: str = 'ja', 
                        trace_id: Optional[str] = None) -> List[Dict]:
        """
        ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£èªè­˜ï¼ˆäººåã€åœ°åã€çµ„ç¹”åãªã©ï¼‰
        
        Args:
            text: åˆ†æå¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ
            language_code: è¨€èªã‚³ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'ja'ï¼‰
            trace_id: ãƒˆãƒ¬ãƒ¼ã‚¹IDï¼ˆç›£æŸ»ãƒ­ã‚°ç”¨ã€ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        
        Returns:
            List[Dict]: [
                {
                    'Type': 'PERSON',  # PERSON, LOCATION, ORGANIZATION, DATE, etc.
                    'Text': 'å±±ç”°å¤ªéƒ',
                    'Score': 0.98,
                    'BeginOffset': 0,
                    'EndOffset': 4
                }, ...
            ]
        """
        if not text or not text.strip():
            logger.warning("Empty text provided for entity extraction")
            return []
        
        try:
            response = self.comprehend.detect_entities(
                Text=text,
                LanguageCode=language_code
            )
            return response['Entities']
        except ClientError as e:
            error_code = e.response['Error']['Code']
            # P0ä¿®æ­£1: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‹ã‚‰æ©Ÿå¯†æƒ…å ±ã‚’é™¤å¤–
            logger.error(f"Entity extraction error: {error_code}", 
                       extra={'trace_id': trace_id})
            return []
        except Exception as e:
            # P0ä¿®æ­£1: æ©Ÿå¯†æƒ…å ±ã‚’ãƒã‚¹ã‚¯
            safe_message = self._mask_sensitive_info(str(e))
            logger.error(f"Unexpected error in extract_entities: {safe_message}", 
                       extra={'trace_id': trace_id})
            return []
    
    def analyze_text_comprehensive(self, text: str, language_code: str = 'ja', 
                                   include_pii: bool = False) -> Dict:
        """
        åŒ…æ‹¬çš„ãƒ†ã‚­ã‚¹ãƒˆåˆ†æï¼ˆæ„Ÿæƒ…ãƒ»ã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ã‚ºãƒ»ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ï¼‰
        
        Args:
            text: åˆ†æå¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ
            language_code: è¨€èªã‚³ãƒ¼ãƒ‰ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'ja'ï¼‰
            include_pii: PIIæ¤œå‡ºã‚’å«ã‚ã‚‹ã‹ï¼ˆè‹±èª/ã‚¹ãƒšã‚¤ãƒ³èªã®ã¿ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Falseï¼‰
        
        Returns:
            Dict: {
                'sentiment': {...},
                'key_phrases': [...],
                'entities': [...],
                'pii': {...}  # include_pii=True ã®å ´åˆã®ã¿
            }
        """
        result = {
            'sentiment': self.analyze_sentiment(text, language_code),
            'key_phrases': self.extract_key_phrases(text, language_code),
            'entities': self.extract_entities(text, language_code)
        }
        
        if include_pii and language_code in ['en', 'es']:
            masked_text, pii_metadata = self.mask_with_comprehend(
                text, use_comprehend=True, language_code=language_code
            )
            result['pii'] = {
                'masked_text': masked_text,
                'metadata': pii_metadata
            }
        
        return result


def main():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("=" * 70)
    print("Amazon Comprehendçµ±åˆ - åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆå®Ÿè¡Œï¼ˆPhase 2æ‹¡å¼µç‰ˆï¼‰")
    print("=" * 70)
    
    masker = ComprehendPIIMasker(confidence_threshold=0.7)
    
    # ãƒ†ã‚¹ãƒˆ1: æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆï¼ˆæ­£è¦è¡¨ç¾ã®ã¿PIIæ¤œå‡ºï¼‰
    test_text_ja = """
ãŠå•ã„åˆã‚ã›ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€‚
ãƒ¡ãƒ¼ãƒ«: test@example.com
é›»è©±: 03-1234-5678
ãƒã‚¤ãƒŠãƒ³ãƒãƒ¼: 1234-5678-9012
ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰: 1234 5678 9012 3456
éƒµä¾¿ç•ªå·: 123-4567
    """
    
    print("\n=== ãƒ†ã‚¹ãƒˆ1: æ—¥æœ¬èªPIIæ¤œå‡ºï¼ˆæ­£è¦è¡¨ç¾ã®ã¿ï¼‰ ===")
    print("å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ:")
    print(test_text_ja)
    
    masked_text_ja, metadata_ja = masker.mask_with_comprehend(
        test_text_ja, 
        use_comprehend=False  # æ—¥æœ¬èªã¯éå¯¾å¿œã®ãŸã‚æ­£è¦è¡¨ç¾ã®ã¿
    )
    
    print("\nãƒã‚¹ã‚¯æ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆ:")
    print(masked_text_ja)
    print(f"\næ¤œå‡ºæ–¹æ³•: {metadata_ja['method']}")
    print(f"Comprehendæ¤œå‡º: {metadata_ja['comprehend_detected']}")
    print(f"æ­£è¦è¡¨ç¾æ¤œå‡º: {metadata_ja['regex_detected']}")
    print(f"åˆè¨ˆãƒã‚¹ã‚¯æ•°: {metadata_ja['total_masked']}")
    
    # ãƒ†ã‚¹ãƒˆ2: è‹±èªãƒ†ã‚­ã‚¹ãƒˆï¼ˆComprehend + æ­£è¦è¡¨ç¾ï¼‰
    test_text_en = "Email: test@example.com, Phone: 123-456-7890, SSN: 123-45-6789"
    
    print("\n" + "=" * 70)
    print("=== ãƒ†ã‚¹ãƒˆ2: è‹±èªPIIæ¤œå‡ºï¼ˆComprehend + æ­£è¦è¡¨ç¾ï¼‰ ===")
    print("å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ:")
    print(test_text_en)
    
    masked_text_en, metadata_en = masker.mask_with_comprehend(
        test_text_en,
        use_comprehend=True,  # è‹±èªã¯Comprehendå¯¾å¿œ
        language_code='en'
    )
    
    print("\nãƒã‚¹ã‚¯æ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆ:")
    print(masked_text_en)
    print(f"\næ¤œå‡ºæ–¹æ³•: {metadata_en['method']}")
    print(f"Comprehendæ¤œå‡º: {metadata_en['comprehend_detected']}")
    print(f"æ­£è¦è¡¨ç¾æ¤œå‡º: {metadata_en['regex_detected']}")
    print(f"åˆè¨ˆãƒã‚¹ã‚¯æ•°: {metadata_en['total_masked']}")
    
    # ãƒ†ã‚¹ãƒˆ3: æ—¥æœ¬èªæ„Ÿæƒ…åˆ†æ
    test_sentiment_ja = "ä»Šæ—¥ã¯ã¨ã¦ã‚‚è‰¯ã„å¤©æ°—ã§ã€ç´ æ™´ã‚‰ã—ã„ä¸€æ—¥ã§ã—ãŸã€‚"
    
    print("\n" + "=" * 70)
    print("=== ãƒ†ã‚¹ãƒˆ3: æ—¥æœ¬èªæ„Ÿæƒ…åˆ†æ ===")
    print(f"ãƒ†ã‚­ã‚¹ãƒˆ: {test_sentiment_ja}")
    
    sentiment_ja = masker.analyze_sentiment(test_sentiment_ja, language_code='ja')
    if sentiment_ja:
        print(f"\næ„Ÿæƒ…: {sentiment_ja['Sentiment']}")
        print("ã‚¹ã‚³ã‚¢:")
        for key, value in sentiment_ja['SentimentScore'].items():
            print(f"  {key}: {value:.4f}")
    
    # ãƒ†ã‚¹ãƒˆ4: æ—¥æœ¬èªã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ã‚ºæŠ½å‡º
    test_keyphrases_ja = """
AWSã®Amazon Comprehendã¯è‡ªç„¶è¨€èªå‡¦ç†ã‚µãƒ¼ãƒ“ã‚¹ã§ã™ã€‚
æ©Ÿæ¢°å­¦ç¿’ã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ´å¯Ÿã‚’è¦‹ã¤ã‘ã¾ã™ã€‚
"""
    
    print("\n" + "=" * 70)
    print("=== ãƒ†ã‚¹ãƒˆ4: æ—¥æœ¬èªã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ã‚ºæŠ½å‡º ===")
    print("ãƒ†ã‚­ã‚¹ãƒˆ:")
    print(test_keyphrases_ja)
    
    key_phrases = masker.extract_key_phrases(test_keyphrases_ja, language_code='ja')
    if key_phrases:
        print(f"\næŠ½å‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ã‚ºï¼ˆä¸Šä½5ä»¶ï¼‰:")
        for phrase in sorted(key_phrases, key=lambda x: x['Score'], reverse=True)[:5]:
            print(f"  - {phrase['Text']} (ã‚¹ã‚³ã‚¢: {phrase['Score']:.4f})")
    
    # ãƒ†ã‚¹ãƒˆ5: æ—¥æœ¬èªã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£èªè­˜
    test_entities_ja = """
å±±ç”°å¤ªéƒã•ã‚“ã¯æ±äº¬éƒ½åƒä»£ç”°åŒºã«ã‚ã‚‹ABCæ ªå¼ä¼šç¤¾ã«å‹¤å‹™ã—ã¦ã„ã¾ã™ã€‚
2025å¹´11æœˆ20æ—¥ã«æ–°ã—ã„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒé–‹å§‹ã•ã‚Œã¾ã™ã€‚
"""
    
    print("\n" + "=" * 70)
    print("=== ãƒ†ã‚¹ãƒˆ5: æ—¥æœ¬èªã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£èªè­˜ ===")
    print("ãƒ†ã‚­ã‚¹ãƒˆ:")
    print(test_entities_ja)
    
    entities = masker.extract_entities(test_entities_ja, language_code='ja')
    if entities:
        print(f"\nèªè­˜ã•ã‚ŒãŸã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£:")
        for entity in entities:
            print(f"  - {entity['Text']} ({entity['Type']}, ã‚¹ã‚³ã‚¢: {entity['Score']:.4f})")
    
    # ãƒ†ã‚¹ãƒˆ6: åŒ…æ‹¬çš„ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ
    test_comprehensive = "ä»Šæ—¥ã¯ç´ æ™´ã‚‰ã—ã„ä¼šè­°ã§ã—ãŸã€‚ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®ç”°ä¸­ã•ã‚“ãŒç´ æ™´ã‚‰ã—ã„ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ã—ã¾ã—ãŸã€‚"
    
    print("\n" + "=" * 70)
    print("=== ãƒ†ã‚¹ãƒˆ6: åŒ…æ‹¬çš„ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ ===")
    print(f"ãƒ†ã‚­ã‚¹ãƒˆ: {test_comprehensive}")
    
    comprehensive_result = masker.analyze_text_comprehensive(
        test_comprehensive, 
        language_code='ja',
        include_pii=False
    )
    
    print("\nåŒ…æ‹¬çš„åˆ†æçµæœ:")
    print(f"  æ„Ÿæƒ…: {comprehensive_result['sentiment']['Sentiment'] if comprehensive_result['sentiment'] else 'N/A'}")
    print(f"  ã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ã‚ºæ•°: {len(comprehensive_result['key_phrases'])}")
    print(f"  ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ•°: {len(comprehensive_result['entities'])}")
    
    print("\n" + "=" * 70)
    print("âœ… å…¨ãƒ†ã‚¹ãƒˆå®Œäº†ï¼ˆPhase 2æ‹¡å¼µç‰ˆï¼‰")
    print("=" * 70)
    print("\nğŸ“‹ æ©Ÿèƒ½ãƒªã‚¹ãƒˆ:")
    print("  âœ… PIIæ¤œå‡ºï¼ˆComprehend + æ­£è¦è¡¨ç¾ï¼‰")
    print("  âœ… æ„Ÿæƒ…åˆ†æ")
    print("  âœ… ã‚­ãƒ¼ãƒ•ãƒ¬ãƒ¼ã‚ºæŠ½å‡º")
    print("  âœ… ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£èªè­˜")
    print("  âœ… åŒ…æ‹¬çš„ãƒ†ã‚­ã‚¹ãƒˆåˆ†æ")
    print("\nâš ï¸ æ³¨æ„: Comprehend PIIæ¤œå‡ºã¯è‹±èª/ã‚¹ãƒšã‚¤ãƒ³èªã®ã¿å¯¾å¿œ")
    print("   æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã¯æ­£è¦è¡¨ç¾ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„")


if __name__ == '__main__':
    main()
